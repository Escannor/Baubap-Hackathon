{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score, brier_score_loss\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2563, 117) (2563,)\n"
     ]
    }
   ],
   "source": [
    "X = joblib.load('../data/X_training.joblib')\n",
    "y = joblib.load('../data/y_training.joblib')\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'weights': 'uniform', 'n_neighbors': 17, 'metric': 'manhattan'}\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8917073170731707\n",
      "- MCC: 0.0\n",
      "- F1 score: 0.8406606372407202\n",
      "- Brier score: 0.10829268292682927\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8908382066276803\n",
      "- MCC: 0.0\n",
      "- F1 score: 0.8394083720182473\n",
      "- Brier score: 0.10916179337231968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': np.arange(1, 25),            # Rango de vecinos\n",
    "    'weights': ['uniform', 'distance'],         # Opciones de pesos\n",
    "    'metric': ['euclidean', 'manhattan']        # Opciones de métricas de distancia\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train) # Train model\n",
    "\n",
    "knn = random_search.best_estimator_ \n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "knn_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "knn_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "knn_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "knn_train_brier = brier_score_loss(y_train, y_train_pred) # Calculate Brier Score\n",
    "\n",
    "# Test set performance\n",
    "knn_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "knn_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "knn_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "knn_test_brier = brier_score_loss(y_test, y_test_pred) # Calculate Brier Score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % knn_train_accuracy)\n",
    "print('- MCC: %s' % knn_train_mcc)\n",
    "print('- F1 score: %s' % knn_train_f1)\n",
    "print('- Brier score: %s' % knn_train_brier)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % knn_test_accuracy)\n",
    "print('- MCC: %s' % knn_test_mcc)\n",
    "print('- F1 score: %s' % knn_test_f1)\n",
    "print('- Brier score: %s' % knn_test_brier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machine (Radial basis function kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'kernel': 'rbf', 'gamma': 1000.0, 'C': 0.01}\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8917073170731707\n",
      "- MCC: 0.0\n",
      "- F1 score: 0.8406606372407202\n",
      "- Brier score: 0.10829268292682927\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8908382066276803\n",
      "- MCC: 0.0\n",
      "- F1 score: 0.8394083720182473\n",
      "- Brier score: 0.10916179337231968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 3, 7),            # Parámetro de regularización\n",
    "    'gamma': np.logspace(-3, 3, 7),         # Parámetro del kernel RBF\n",
    "    'kernel': ['rbf']            # Tipo de kernel  ['linear', 'rbf'] \n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "svm_rbf = random_search.best_estimator_ \n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = svm_rbf.predict(X_train)\n",
    "y_test_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "svm_rbf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "svm_rbf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "svm_rbf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "svm_rbf_train_brier = brier_score_loss(y_train, y_train_pred) # Calculate Brier Score\n",
    "\n",
    "# Test set performance\n",
    "svm_rbf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "svm_rbf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "svm_rbf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "svm_rbf_test_brier = brier_score_loss(y_test, y_test_pred) # Calculate Brier Score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % svm_rbf_train_accuracy)\n",
    "print('- MCC: %s' % svm_rbf_train_mcc)\n",
    "print('- F1 score: %s' % svm_rbf_train_f1)\n",
    "print('- Brier score: %s' % svm_rbf_train_brier)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % svm_rbf_test_accuracy)\n",
    "print('- MCC: %s' % svm_rbf_test_mcc)\n",
    "print('- F1 score: %s' % svm_rbf_test_f1)\n",
    "print('- Brier score: %s' % svm_rbf_test_brier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 2, 'criterion': 'gini'}\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.895609756097561\n",
      "- MCC: 0.1831516293298143\n",
      "- F1 score: 0.8532165659079183\n",
      "- Brier score: 0.10439024390243902\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8908382066276803\n",
      "- MCC: 0.07840916178976971\n",
      "- F1 score: 0.8430663118008441\n",
      "- Brier score: 0.10916179337231968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': np.arange(1, 24),            # Profundidad máxima del árbol\n",
    "    'min_samples_split': np.arange(2, 12),    # Número mínimo de muestras requeridas para dividir un nodo interno\n",
    "    'min_samples_leaf': np.arange(1, 12),     # Número mínimo de muestras requeridas para estar en un nodo hoja\n",
    "    'criterion': ['gini', 'entropy']          # Criterio de división ('gini' o 'entropy')\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train) # Train model\n",
    "\n",
    "dt = random_search.best_estimator_ \n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "dt_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "dt_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "dt_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "dt_train_brier = brier_score_loss(y_train, y_train_pred) # Calculate Brier Score\n",
    "\n",
    "# Test set performance\n",
    "dt_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "dt_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "dt_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "dt_test_brier = brier_score_loss(y_test, y_test_pred) # Calculate Brier Score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % dt_train_accuracy)\n",
    "print('- MCC: %s' % dt_train_mcc)\n",
    "print('- F1 score: %s' % dt_train_f1)\n",
    "print('- Brier score: %s' % dt_train_brier)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % dt_test_accuracy)\n",
    "print('- MCC: %s' % dt_test_mcc)\n",
    "print('- F1 score: %s' % dt_test_f1)\n",
    "print('- Brier score: %s' % dt_test_brier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.89073171        nan 0.89073171        nan        nan        nan\n",
      "        nan 0.8902439  0.89121951        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 40, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': None, 'max_depth': 16}\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8980487804878049\n",
      "- MCC: 0.22923861195299328\n",
      "- F1 score: 0.8554695331743167\n",
      "- Brier score: 0.10195121951219512\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8927875243664717\n",
      "- MCC: 0.1262493369855292\n",
      "- F1 score: 0.8441048728920111\n",
      "- Brier score: 0.10721247563352826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(10, 200, 10),          # Número de árboles en el bosque\n",
    "    'max_depth': np.arange(1, 21),                   # Profundidad máxima de los árboles\n",
    "    'min_samples_split': np.arange(2, 10),           # Número mínimo de muestras requeridas para dividir un nodo\n",
    "    'min_samples_leaf': np.arange(1, 10),            # Número mínimo de muestras requeridas en un nodo hoja\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]  # Número máximo de características consideradas para dividir un nodo\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train) # Train model\n",
    "\n",
    "rf = random_search.best_estimator_ \n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "rf_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "rf_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "rf_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "rf_train_brier = brier_score_loss(y_train, y_train_pred) # Calculate Brier Score\n",
    "\n",
    "# Test set performance\n",
    "rf_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "rf_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "rf_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "rf_test_brier = brier_score_loss(y_test, y_test_pred) # Calculate Brier Score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % rf_train_accuracy)\n",
    "print('- MCC: %s' % rf_train_mcc)\n",
    "print('- F1 score: %s' % rf_train_f1)\n",
    "print('- Brier score: %s' % rf_train_brier)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % rf_test_accuracy)\n",
    "print('- MCC: %s' % rf_test_mcc)\n",
    "print('- F1 score: %s' % rf_test_f1)\n",
    "print('- Brier score: %s' % rf_test_brier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_iter': 400, 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 50), 'alpha': 1.0, 'activation': 'logistic'}\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8917073170731707\n",
      "- MCC: 0.0\n",
      "- F1 score: 0.8406606372407202\n",
      "- Brier score: 0.10829268292682927\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8908382066276803\n",
      "- MCC: 0.0\n",
      "- F1 score: 0.8394083720182473\n",
      "- Brier score: 0.10916179337231968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50, 25)],  # Tamaños de las capas ocultas\n",
    "    'activation': ['logistic', 'tanh', 'relu'],                          # Funciones de activación\n",
    "    'alpha': np.logspace(-5, 3, 9),                                     # Término de regularización L2\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],             # Tasa de aprendizaje\n",
    "    'max_iter': np.arange(200, 1401, 100)                                # Número máximo de iteraciones\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(MLPClassifier(), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train) # Train model\n",
    "\n",
    "mlp = random_search.best_estimator_ \n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "mlp_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "mlp_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "mlp_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "mlp_train_brier = brier_score_loss(y_train, y_train_pred) # Calculate Brier Score\n",
    "\n",
    "# Test set performance\n",
    "mlp_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "mlp_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "mlp_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "mlp_test_brier = brier_score_loss(y_test, y_test_pred) # Calculate Brier Score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % mlp_train_accuracy)\n",
    "print('- MCC: %s' % mlp_train_mcc)\n",
    "print('- F1 score: %s' % mlp_train_f1)\n",
    "print('- Brier score: %s' % mlp_train_brier)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % mlp_test_accuracy)\n",
    "print('- MCC: %s' % mlp_test_mcc)\n",
    "print('- F1 score: %s' % mlp_test_f1)\n",
    "print('- Brier score: %s' % mlp_test_brier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'subsample': 1.0, 'n_estimators': 160, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 1, 'colsample_bytree': 0.9}\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9034146341463415\n",
      "- MCC: 0.31231835520165085\n",
      "- F1 score: 0.8670259597250877\n",
      "- Brier score: 0.09658536585365854\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8927875243664717\n",
      "- MCC: 0.1262493369855292\n",
      "- F1 score: 0.8441048728920111\n",
      "- Brier score: 0.10721247563352826\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 200, 10),          # Número de árboles\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],         # Tasa de aprendizaje\n",
    "    'max_depth': np.arange(3, 10),                   # Profundidad máxima del árbol\n",
    "    'subsample': [0.8, 0.9, 1.0],                   # Proporción de muestras utilizadas para entrenar cada árbol\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],            # Proporción de características utilizadas para entrenar cada árbol\n",
    "    'gamma': [0, 1, 2]                              # Parámetro de regularización para controlar la complejidad del árbol\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(XGBClassifier(), param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train, y_train) # Train model\n",
    "\n",
    "xgbc = random_search.best_estimator_ \n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = xgbc.predict(X_train)\n",
    "y_test_pred = xgbc.predict(X_test)\n",
    "\n",
    "# Training set performance\n",
    "xgbc_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "xgbc_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "xgbc_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "xgbc_train_brier = brier_score_loss(y_train, y_train_pred) # Calculate Brier Score\n",
    "\n",
    "# Test set performance\n",
    "xgbc_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "xgbc_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "xgbc_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "xgbc_test_brier = brier_score_loss(y_test, y_test_pred) # Calculate Brier Score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % xgbc_train_accuracy)\n",
    "print('- MCC: %s' % xgbc_train_mcc)\n",
    "print('- F1 score: %s' % xgbc_train_f1)\n",
    "print('- Brier score: %s' % xgbc_train_brier)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % xgbc_test_accuracy)\n",
    "print('- MCC: %s' % xgbc_test_mcc)\n",
    "print('- F1 score: %s' % xgbc_test_f1)\n",
    "print('- Brier score: %s' % xgbc_test_brier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 0.8941463414634147\n",
      "- MCC: 0.1418894007306131\n",
      "- F1 score: 0.8465165235620662\n",
      "- Brier score: 0.10585365853658536\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8908382066276803\n",
      "- MCC: 0.0\n",
      "- F1 score: 0.8394083720182473\n",
      "- Brier score: 0.10585365853658536\n"
     ]
    }
   ],
   "source": [
    "# Define estimators\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator_list = [\n",
    "    ('knn',knn),\n",
    "    ('svm_rbf',svm_rbf),\n",
    "    ('dt',dt),\n",
    "    ('rf',rf),\n",
    "    ('mlp',mlp), \n",
    "    ('xgbc',xgbc) ]\n",
    "\n",
    "# Build stack model\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=estimator_list, final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = stack_model.predict(X_train)\n",
    "y_test_pred = stack_model.predict(X_test)\n",
    "\n",
    "# Training set model performance\n",
    "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "stack_model_train_brier = brier_score_loss(y_train, y_train_pred) # Calculate Brier Score\n",
    "\n",
    "# Test set model performance\n",
    "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "stack_model_test_brier = brier_score_loss(y_train, y_train_pred) # Calculate Brier Score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
    "print('- MCC: %s' % stack_model_train_mcc)\n",
    "print('- F1 score: %s' % stack_model_train_f1)\n",
    "print('- Brier score: %s' % stack_model_train_brier)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
    "print('- MCC: %s' % stack_model_test_mcc)\n",
    "print('- F1 score: %s' % stack_model_test_f1)\n",
    "print('- Brier score: %s' % stack_model_test_brier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_list = {'knn':knn_train_accuracy,\n",
    "'svm_rbf': svm_rbf_train_accuracy,\n",
    "'dt': dt_train_accuracy,\n",
    "'rf': rf_train_accuracy,\n",
    "'mlp': mlp_train_accuracy,\n",
    "'xgbc': xgbc_train_accuracy,\n",
    "'stack': stack_model_train_accuracy}\n",
    "\n",
    "mcc_train_list = {'knn':knn_train_mcc,\n",
    "'svm_rbf': svm_rbf_train_mcc,\n",
    "'dt': dt_train_mcc,\n",
    "'rf': rf_train_mcc,\n",
    "'mlp': mlp_train_mcc,\n",
    "'xgbc': xgbc_train_mcc,\n",
    "'stack': stack_model_train_mcc}\n",
    "\n",
    "f1_train_list = {'knn':knn_train_f1,\n",
    "'svm_rbf': svm_rbf_train_f1,\n",
    "'dt': dt_train_f1,\n",
    "'rf': rf_train_f1,\n",
    "'mlp': mlp_train_f1,\n",
    "'xgbc': xgbc_train_f1,\n",
    "'stack': stack_model_train_f1}\n",
    "\n",
    "brier_train_list = {'knn':knn_train_brier,\n",
    "'svm_rbf': svm_rbf_train_brier,\n",
    "'dt': dt_train_brier,\n",
    "'rf': rf_train_brier,\n",
    "'mlp': mlp_train_brier,\n",
    "'xgbc': xgbc_train_brier,\n",
    "'stack': stack_model_train_brier}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.891707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840661</td>\n",
       "      <td>0.108293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_rbf</th>\n",
       "      <td>0.891707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840661</td>\n",
       "      <td>0.108293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.895610</td>\n",
       "      <td>0.183152</td>\n",
       "      <td>0.853217</td>\n",
       "      <td>0.104390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.898049</td>\n",
       "      <td>0.229239</td>\n",
       "      <td>0.855470</td>\n",
       "      <td>0.101951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.891707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.840661</td>\n",
       "      <td>0.108293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgbc</th>\n",
       "      <td>0.903415</td>\n",
       "      <td>0.312318</td>\n",
       "      <td>0.867026</td>\n",
       "      <td>0.096585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stack</th>\n",
       "      <td>0.894146</td>\n",
       "      <td>0.141889</td>\n",
       "      <td>0.846517</td>\n",
       "      <td>0.105854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy       MCC        F1     Brier\n",
       "knn      0.891707  0.000000  0.840661  0.108293\n",
       "svm_rbf  0.891707  0.000000  0.840661  0.108293\n",
       "dt       0.895610  0.183152  0.853217  0.104390\n",
       "rf       0.898049  0.229239  0.855470  0.101951\n",
       "mlp      0.891707  0.000000  0.840661  0.108293\n",
       "xgbc     0.903415  0.312318  0.867026  0.096585\n",
       "stack    0.894146  0.141889  0.846517  0.105854"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.DataFrame.from_dict(acc_train_list, orient='index', columns=['Accuracy'])\n",
    "mcc_df = pd.DataFrame.from_dict(mcc_train_list, orient='index', columns=['MCC'])\n",
    "f1_df = pd.DataFrame.from_dict(f1_train_list, orient='index', columns=['F1'])\n",
    "brier_df = pd.DataFrame.from_dict(brier_train_list, orient='index', columns=['Brier'])\n",
    "df = pd.concat([acc_df, mcc_df, f1_df, brier_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test_list = {'knn':knn_test_accuracy,\n",
    "'svm_rbf': svm_rbf_test_accuracy,\n",
    "'dt': dt_test_accuracy,\n",
    "'rf': rf_test_accuracy,\n",
    "'mlp': mlp_test_accuracy,\n",
    "'xgbc': xgbc_test_accuracy,\n",
    "'stack': stack_model_test_accuracy}\n",
    "\n",
    "mcc_test_list = {'knn':knn_test_mcc,\n",
    "'svm_rbf': svm_rbf_test_mcc,\n",
    "'dt': dt_test_mcc,\n",
    "'rf': rf_test_mcc,\n",
    "'mlp': mlp_test_mcc,\n",
    "'xgbc': xgbc_test_mcc,\n",
    "'stack': stack_model_test_mcc}\n",
    "\n",
    "f1_test_list = {'knn':knn_test_f1,\n",
    "'svm_rbf': svm_rbf_test_f1,\n",
    "'dt': dt_test_f1,\n",
    "'rf': rf_test_f1,\n",
    "'mlp': mlp_test_f1,\n",
    "'xgbc': xgbc_test_f1,\n",
    "'stack': stack_model_test_f1}\n",
    "\n",
    "brier_test_list = {'knn':knn_test_brier,\n",
    "'svm_rbf': svm_rbf_test_brier,\n",
    "'dt': dt_test_brier,\n",
    "'rf': rf_test_brier,\n",
    "'mlp': mlp_test_brier,\n",
    "'xgbc': xgbc_test_brier,\n",
    "'stack': stack_model_test_brier}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.890838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.839408</td>\n",
       "      <td>0.109162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm_rbf</th>\n",
       "      <td>0.890838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.839408</td>\n",
       "      <td>0.109162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.890838</td>\n",
       "      <td>0.078409</td>\n",
       "      <td>0.843066</td>\n",
       "      <td>0.109162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.892788</td>\n",
       "      <td>0.126249</td>\n",
       "      <td>0.844105</td>\n",
       "      <td>0.107212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.890838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.839408</td>\n",
       "      <td>0.109162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgbc</th>\n",
       "      <td>0.892788</td>\n",
       "      <td>0.126249</td>\n",
       "      <td>0.844105</td>\n",
       "      <td>0.107212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stack</th>\n",
       "      <td>0.890838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.839408</td>\n",
       "      <td>0.105854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy       MCC        F1     Brier\n",
       "knn      0.890838  0.000000  0.839408  0.109162\n",
       "svm_rbf  0.890838  0.000000  0.839408  0.109162\n",
       "dt       0.890838  0.078409  0.843066  0.109162\n",
       "rf       0.892788  0.126249  0.844105  0.107212\n",
       "mlp      0.890838  0.000000  0.839408  0.109162\n",
       "xgbc     0.892788  0.126249  0.844105  0.107212\n",
       "stack    0.890838  0.000000  0.839408  0.105854"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df = pd.DataFrame.from_dict(acc_test_list, orient='index', columns=['Accuracy'])\n",
    "mcc_df = pd.DataFrame.from_dict(mcc_test_list, orient='index', columns=['MCC'])\n",
    "f1_df = pd.DataFrame.from_dict(f1_test_list, orient='index', columns=['F1'])\n",
    "brier_df = pd.DataFrame.from_dict(brier_test_list, orient='index', columns=['Brier'])\n",
    "df = pd.concat([acc_df, mcc_df, f1_df, brier_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/stack_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo en un archivo\n",
    "joblib.dump(svm_rbf, '../models/svm_model.joblib')\n",
    "joblib.dump(xgbc, '../models/xgbc_model.joblib')\n",
    "joblib.dump(stack_model, '../models/stack_model.joblib')\n",
    "\n",
    "# Guardar listado de features para el modelo\n",
    "# joblib.dump(selected_columns, '../models/list_of_features.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
